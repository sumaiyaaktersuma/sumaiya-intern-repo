# Use of AI Tools – Reflection

## Goal
Understand how to responsibly and effectively use AI tools while maintaining data privacy and critical thinking.

## Why is this important?
By producing drafts, automating repetitive processes, and assisting with analysis, AI systems can increase productivity. On the other hand, abuse—like inputting private information or heedlessly depending on AI results—can result in inaccurate information, poor decision-making, or privacy violations. Utilising AI responsibly guarantees that we gain from it while safeguarding private data.

## Research & Learn

**AI Tools for My Role (Cyber Security Analyst):**  
- **ChatGPT / Copilot / Gemini** – for summarising logs, drafting documentation, or generating security checklists.  
- **AI-driven SIEM features** (e.g., Microsoft Sentinel, Splunk) – for identifying anomalies in security logs.  
- **Threat intelligence AI tools** – to detect patterns or emerging attack trends.  

**Benefits of AI in a Professional Setting:**  
- Saves time in research and documentation.  
- Automates repetitive analysis (e.g., log correlation, summarisation).  
- Provides brainstorming support and different perspectives.  

**Risks of AI Use:**  
- Possible leakage of confidential or personal data.  
- Inaccuracies or “hallucinations” in generated outputs.  
- Risk of over-reliance, reducing critical thinking.  

**Information Never to Enter Into AI Tools:**  
- User data (emails, passwords, logs with identifiers).  
- Financial/payment details.  
- Proprietary source code or system configurations.  
- Internal company documents or strategies not already public.  

**Fact-Checking & Validation Steps:**  
- Cross-check AI outputs against **official sources** (docs, policies, logs).  
- Validate technical details with **manual testing** or reliable cybersecurity references.  
- Use AI as a **support tool**, not a decision-maker.  

## Reflection

**When to use AI vs. my own skills:**  
- For **support tasks**, such as creating checklists, summarising lengthy logs, and writing reports, I'll employ AI.  
- For **core tasks** where accuracy and secrecy are crucial, such as log analysis, security incident response, and vulnerability testing, I will rely on my own abilities.  

**Avoiding Over-Reliance:**  
- AI recommendations should be viewed as a *first draft* rather than the definitive solution.  
- Verify technical advice at all times.  
- AI should be used to expedite work rather than to take the place of problem-solving abilities.  
**Ensuring Data Privacy:**  
- Never enter user-identified or sensitive data into AI programmes.  
- Before using AI to summarise, remove username and IP logs.  
- Use AI only in accordance with GDPR compliance and Focus Bear's privacy policy.  

## Task
**AI Task Tried:**  
I used ChatGPT to generate a **template for bug reports** to improve clarity when documenting QA/security issues.  

**Review of Output:**  
- The draft saved time and was helpful. 
- I still needed to eliminate extraneous parts, add actual instances, and revise it for authenticity.  

**Best Practice Going Forward:**  
Prior to employing AI, I will always **anonymize and fact-check data**. I will regard AI as a *support tool* and make sure it is reviewed by a human before sharing it with the team if I use it for drafting or summing.